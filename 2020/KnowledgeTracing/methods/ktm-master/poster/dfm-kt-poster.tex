\documentclass[25pt, a0paper,
margin=0mm, innermargin=15mm, blockverticalspace=5mm, colspace=15mm, subcolspace=1mm]{tikzposter}
\usepackage{trace}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{mathtools}
\usepackage{cmbright}
\usepackage[backend=biber]{biblatex}
\addbibresource{dfm-biblio.bib}
\usepackage{fontspec}
\usepackage{bm}
\newfontfeature{Microtype}{protrusion=default;expansion=default;}
\tikzposterlatexaffectionproofoff

\DeclareMathOperator\logit{logit}
\DeclareMathOperator\probit{probit}
\def\R{\mathbf{R}}
\def\N{\mathcal{N}}
\def\ReLU{\textnormal{ReLU}}
\def\pij{p_{ij}}
\def\logitp{\logit{} p_{ij}}

\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{hyperref}
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    citecolor={blue!80!black},
}
\newcommand{\email}[1]{\href{mailto:#1}{\textsf{#1}}}
\title{\parbox{\linewidth}{\begin{center}\textbf{Deep Factorization Machines for Knowledge Tracing}\end{center}}}
\author{\centering
  \begin{tabular}{cc}
    \textbf{Jill-Jênn Vie} \\
    RIKEN Center for Advanced Intelligence Project (AIP)\\
Tokyo, Japan\\
\texttt{vie@jill-jenn.net}
  \end{tabular}
    }

\usetheme{Simple}

\usecolorpalette{BrownBlueOrange}
\makeatletter
\renewcommand\TP@maketitle{
   \begin{minipage}{0.98\linewidth}
        \centering
        \color{titlefgcolor}
        {\bfseries \Huge \sc \@title \par}
        \vspace*{1em}
        {\Large
          \@author \par}
    \end{minipage}
}
\makeatother

\usepackage{theorem}
\theoremstyle{myplain}
\newtheorem{transformation}{Transformation}
\newcommand{\concprio}{\rangle\kern-0.15em\rangle}

\usepackage{tikz-qtree}

\usetikzlibrary{arrows,arrows.meta,automata,shapes,intersections,mindmap,trees,shadows,fit,positioning,calc,matrix,decorations,chains,external,3d}
\makeatletter
\tikzoption{canvas is xy plane at z}[]{%
\def\tikz@plane@origin{\pgfpointxyz{0}{0}{#1}}%
\def\tikz@plane@x{\pgfpointxyz{1}{0}{#1}}%
\def\tikz@plane@y{\pgfpointxyz{0}{1}{#1}}%
\tikz@canvas@is@plane
}
\makeatother
\usepackage{listings}
\usepackage{enumitem}
\usepackage{booktabs}
\newcommand{\Gproc}{\textbf{proc }}
\newcommand{\GendProc}{\textbf{ endProc}}
\newcommand{\Gif}{\textbf{if }}
\newcommand{\Gthen}{\textbf{ then }}
\newcommand{\Gelse}{\textbf{ else }}
\newcommand{\Gwhile}{\textbf{while }}
\newcommand{\Gdo}{\textbf{ do }}
\newcommand{\mprefer}{\,\rangle\,}
\newcommand{\GendIf}{\textbf{ endIf }}
\newcommand{\GendWhile}{\textbf{ endWhile }}
\newcommand{\affp}{\textit{aff\/}_p}
\newcommand{\set}[1]{\{#1\}}

\newcommand{\Gleft}[1]{G_{#1}^{\textit{left}}}
\newcommand{\Gright}[1]{G_{#1}^{\textit{right}}}
\newcommand{\Gmiddle}[1]{G_{#1}}

\newcommand{\prefer}{\rangle}

\newcommand{\alert}[1]{{\color{red!70!black} #1}}

\newcommand{\bs}{\textbackslash}   % backslash
\newcommand{\cmd}[1]{{\bf \color{red}#1}}   % highlights command

\graphicspath{{./}{../images/}}

\usenotestyle{Sticky}

\usepackage{mdframed}
\newmdenv[topline=false,bottomline=false,rightline=false,skipabove=0pt,skipbelow=0pt,innertopmargin=0pt,innerbottommargin=0pt]{sidebox}
\def\HyperFirstAtBeginDocument#1{#1}  % lolwut https://tex.stackexchange.com/a/309895/7144

\begin{document}
\maketitle[width=\linewidth,titletotopverticalspace=0pt]

% Here it starts

\definecolor{pixblue}{RGB}{53,81,250}
\colorlet{innerblocktitlebgcolor}{pixblue}

\begin{columns} % Blocks will be placed into columns
    
    \column{.48}
    \block[roundedcorners=40]{Problem: Knowledge Tracing for Language Learning}{
        We want to \alert{predict the correctness} of students over words.\\
        Each student can attempt to write a certain word multiple times, and learns in-between.\\
        \textbf{Fit:} Ordered triplets $(i, j, o) \in I \times J \times \{0, 1\}$\\
        $\Rightarrow$ Student $i$ attempted word $j$ and wrote it correctly/incorrectly.\\
        \textbf{Predict:} $(i, j, ?)$ for new triplets.
    }
    \block[roundedcorners=40]{Existing families of models}{
        \begin{itemize}
            \item \textbf{Prediction of sequences}: Bayesian Knowledge Tracing (BKT $:=$ HMM)\\ Deep Knowledge Tracing (DKT $:=$ LSTM) \autocite{piech2015deep}
            \item \textbf{Factor Analysis}: Item Response Theory (IRT), Performance Factor Analysis (PFA)

            \[ \textnormal{BKT} < \textnormal{PFA} \simeq^{\textnormal{\autocite{xiong2016going}}} \textnormal{DKT} \leq^{\textnormal{\cite{wilson2016back}}} \textnormal{IRT } \alert{\leq^{\textnormal{[this poster]}} \textnormal{FM}} \]

        \end{itemize}

        \vspace{1cm}
        \innerblock[]{Logistic Regression (LR)}{
            All students $i \in I$, questions $j \in J$ and metadata are encoded into sparse features $x$\\
            Each feature $k$ has a bias \alert{$w_k$}
            \[ \logit p(x) = \logit \Pr(\textsf{event } x \textnormal{ has positive outcome}) = \mu + \alert{w^T} x \]

            \hfill $\Rightarrow$ \textnormal{ \textbf{really simple, ignores pairwise interactions} ($d = 0$)}
        }
        Particular cases for user $i$ against token $j$:\\
        Item response theory (IRT): \hfill $\logit{} p_{ij} = \alert{\theta_i} - \alert{d_j}$\\
        Performance Factor Analysis (PFA): \hfill $\logit{} p_{ij} = \sum_{k \in \textnormal{KC}(j)} \alert{\beta_k} + \alert{\gamma_k} W_{ik} + \alert{\delta_k} F_{ik}$\\
        \vspace{1cm}
        \innerblock[]{Factorization Machines (FM)}{
            All students $i \in I$ and questions $j \in J$ and past performance are encoded into $x$\\
            All entities have a bias \alert{$w_k$} and features $\alert{\bm{v_k}} \in \R^d$ to model pairwise interactions

            \[ \psi(p(x)) = \mu + \underbrace{\sum_{k = 1}^N \alert{w_k} x_k}_{\textnormal{logistic regression}} + \underbrace{\sum_{1 \leq k < l \leq N} x_k x_l \langle \alert{\bm{v_k}}, \alert{\bm{v_l}} \rangle}_{\textnormal{pairwise interactions}} \]
            \hfill $\Rightarrow$ \textnormal{ \textbf{converting sparse features to dense embeddings}}
        }
        Particular case:\\
        Multidimensional Item Response Theory (MIRT): \hfill $\logit{} p_{ij}= \langle \alert{\bm{\theta_i}}, \alert{\bm{d_j}} \rangle + \alert{\delta_j}$
    }

    \column{.52}
    \block{Our proposal}{
        % Use Deep \autocite{guo2017deepfm} and Bayesian \autocite{freudenthaler2011bayesian} Factorization Machines \autocite{rendle2012factorization} for this task.
        \innerblock[]{Deep Factorization Machines (DeepFM)}{
            All students $i \in I$ and questions $j \in J$ and past performance are encoded into $x$\\
            \textbf{FM:} All entities have a bias \alert{$w_k$} and features $\alert{\bm{v_k}} \in \R^d$ to model pairwise interactions\\
            \textbf{Deep:} Train layers \alert{$W^{(\ell)}$} and \alert{$b^{(\ell)}$} for each $\ell = 1, \ldots, L$ \autocite{guo2017deepfm}

            \[ \logit p(x) = y_{FM}(x) + y_{DNN}(x) \]
            \begin{equation*}
            \begin{aligned}[c]
            y_{FM}(x) = \mu + \sum_{k = 1}^N \alert{w_k} x_k + \sum_{1 \leq k < l \leq N} x_k x_l \langle \alert{\bm{v_k}}, \alert{\bm{v_l}} \rangle\\
            \end{aligned}
            \quad
            \begin{aligned}[c]
            y_{DNN}(x) = \ReLU(\alert{W^{(L)}} a^{(L)}(x) + \alert{b^{(L)}})\\
            a^{(\ell + 1)}(x) = \ReLU(\alert{W^{(\ell)}} a^{(\ell)}(x) + \alert{b^{(\ell)}})\\
            a^{0}(x) = (\alert{\bm{v_{\texttt{user}}}}, \alert{\bm{v_{\texttt{token}}}}, \ldots, \alert{\bm{v_{\texttt{countries}}}})
            \end{aligned}
            \end{equation*}
        }
        \vspace{1cm}
        \innerblock[]{Bayesian Factorization Machines (Bayesian FM)}{
            \[ \probit p(x) = \mu + \sum_{k = 1}^N \alert{w_k} x_k + \sum_{1 \leq k < l \leq N} x_k x_l \langle \alert{\bm{v_k}}, \alert{\bm{v_l}} \rangle \]
            Hyperpriors: $\alert{w_k}, \alert{v_{kf}} \sim \N(\alert{\mu_f}, 1/\alert{\lambda_f})$, $\alert{\mu_f} \sim \N(0, 1)$, $\alert{\lambda_f} \sim \Gamma(1, 1)$,\\
            Trained using \textbf{Gibbs sampling} \autocite{freudenthaler2011bayesian,rendle2012factorization}
        }
    }

    \block{Encoding of entities}{
        Unsupervised problem becomes a supervised problem:

        \vspace{5mm}
        \begin{center}
        \input{tables/fm-poster}
        \end{center}
        \vspace{1cm}

        \begin{minipage}{0.6\linewidth}
            IRT: \texttt{user} + \texttt{token}\\
            first: \texttt{<discrete features>}\\
            last: \texttt{<discrete features>} + \texttt{time} + \texttt{days}\\
            pfa: \texttt{<discrete features>} + \texttt{wins} + \texttt{fails}
        \end{minipage}
        \begin{minipage}{0.3\linewidth}
            \includegraphics[width=\linewidth]{figures/aip.png}
        \end{minipage}
    }

\end{columns}

\block{Results in AUC on large-scale Duolingo dataset}{
    \centering
    \input{tables/results-fr}
    \input{tables/results-es}
    \input{tables/results-en}
}

\begin{columns}
\column{.33}
\block{Take home message}{
    \begin{itemize}
    \item Pairwise interactions are useful
    \item Deep does not help much
    \item Time and days harm
    \end{itemize}
    \vspace{-1cm}
}
\block{Optimizing Human Learning}{
    We are organizing a workshop in Montréal on \textbf{June 12}:\\
    Proceedings on \url{humanlearn.io}
}

\column{.67}
\block{References}{
    \printbibliography[heading=none]
}
\end{columns}

\end{document}

\endinput
